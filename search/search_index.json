{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Catalog","text":"<p>Catalog is a Python command-line-interface (CLI) that automates discovery and understanding of Forest Service geospatial and tabular data. It harvests XML metadata and MapServer service definitions from three anonymized portals\u2014Research Data Archive (RDA), Geospatial Data Discovery (GDD), and FSGeodata Clearinghouse (FSGeodata)\u2014builds embeddings, and allows the user to explore datasets with a semantic, RAG-powered search that can answer questions like \u201cWhat data exists and how do I use it?\u201d.</p>"},{"location":"#why-it-matters","title":"Why it matters","text":"<ul> <li>Hunting across portals, downloading XML one-by-one, and reconciling service URLs slows research and product teams.</li> <li>Explaining lineage and \u201cfit for purpose\u201d to stakeholders is hard without a unified view.</li> <li>Traditional keyword search misses nuance; semantic search with LLMs locates relevant datasets faster.</li> </ul>"},{"location":"#what-catalog-does","title":"What Catalog does","text":"<ul> <li>Automated harvesting from RDA, GDD, and FSGeodata (XML + MapServer JSON).</li> <li>Embeds metadata with a vector database (table) and uses LLMs in a Retrieval-Augmented Generation (RAG) flow for semantic Q&amp;A.</li> <li>Outputs organized metadata and service URLs you can plug into dashboards or analyses.</li> </ul>"},{"location":"#the-process-at-a-glance","title":"The process (at a glance)","text":"<pre><code>flowchart TB\n  Sources[RDA / GDD / FSGeodata] --&gt; Download\n  Download --&gt; Normalize[\"Normalize metadata (XML + JSON)\"]\n  Normalize --&gt; Embed[VectorDB embeddings]\n  Embed --&gt; RAG[LLM + RAG pipeline]\n  RAG --&gt; Answers[Semantic search &amp; dataset guidance]\n</code></pre> <ol> <li>Identify metadata sources:  </li> <li>Research Archive (RDA): research-grade datasets from the agency's research directory.  </li> <li>Geospatial Discovery (GDD): current operational GIS layers and services.  </li> <li> <p>FSGeodata Clearinghouse (FSGeodata): authoritative basemaps, boundaries, operational layers, and raster products.</p> </li> <li> <p>Harvest metadata: <code>uv run catalog download-fs-metadata</code> pulls XML and MapServer JSON, normalizes fields, and stores metadata for indexing.</p> </li> <li> <p>Build the vector database (chromadb): embeddings go into vector storage; metadata stays linked.</p> </li> <li> <p>RAG-based search: the CLI uses the embeddings plus an LLM to answer dataset and lineage questions with grounded citations.</p> </li> </ol>"},{"location":"#where-to-go-next","title":"Where to go next","text":"<ul> <li>Architecture and design decisions: see <code>docs/architecture.md</code>.</li> <li>Data sources deep dive: see <code>docs/data-sources.md</code>.</li> <li>CLI usage and examples: see <code>docs/cli.md</code>.</li> <li>Vector DB details and comparisons: see <code>docs/vector-db.md</code>.</li> </ul>"},{"location":"architecture/","title":"Application Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>Catalog is a Python CLI application that aggregates geospatial metadata from multiple USFS data repositories into a unified, searchable catalog. The system implements a Retrieval-Augmented Generation (RAG) pipeline combining vector-based semantic search with LLM-powered natural language discovery.</p>"},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              CLI Layer                                  \u2502\n\u2502                             (cli.py)                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data Loaders \u2502         \u2502  Vector Store   \u2502         \u2502   LLM Client    \u2502\n\u2502   (usfs.py)   \u2502         \u2502   (core.py)     \u2502         \u2502   (bots.py)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                          \u2502                           \u2502\n        \u25bc                          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Schema     \u2502         \u2502    ChromaDB     \u2502         \u2502     Ollama      \u2502\n\u2502  (schema.py)  \u2502         \u2502                 \u2502         \u2502      API        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#component-descriptions","title":"Component Descriptions","text":""},{"location":"architecture/#cli-layer-clipy","title":"CLI Layer (<code>cli.py</code>)","text":"<p>The entry point for all user interactions. Built with Click framework, it exposes six commands:</p> Command Purpose <code>health</code> System health check <code>download_fs_metadata</code> Fetch raw metadata from all sources <code>build_fs_catalog</code> Parse metadata into unified JSON catalog <code>build_fs_chromadb</code> Index catalog into vector database <code>query_fs_chromadb</code> Semantic search queries <code>ollama_chat</code> LLM-augmented natural language discovery"},{"location":"architecture/#data-loaders-usfspy","title":"Data Loaders (<code>usfs.py</code>)","text":"<p>Orchestrates metadata collection from three federal data sources:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         USFS Class                              \u2502\n\u2502              (Orchestrator for all data sources)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                       \u2502                           \u2502\n        \u25bc                       \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FSGeodataLoader\u2502      \u2502GeospatialData \u2502       \u2502   RDALoader   \u2502\n\u2502               \u2502       \u2502  Discovery    \u2502       \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Source: EDW   \u2502       \u2502 Source: Hub   \u2502       \u2502 Source: RDS   \u2502\n\u2502 Format: XML   \u2502       \u2502 Format: DCAT  \u2502       \u2502 Format: JSON  \u2502\n\u2502 Protocol: HTTP\u2502       \u2502 Protocol: HTTP\u2502       \u2502 Protocol: HTTP\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>FSGeodataLoader</p> <ul> <li>Scrapes dataset index from <code>data.fs.usda.gov</code></li> <li>Downloads FGDC-compliant XML metadata files</li> <li>Retrieves associated MapServer service descriptors</li> <li>Implements rate limiting (250ms delay)</li> </ul> <p>GeospatialDataDiscovery</p> <ul> <li>Fetches DCAT-US 1.1 JSON feed from ArcGIS Hub</li> <li>Single-endpoint bulk download</li> <li>Parses standardized federal open data format</li> </ul> <p>RDALoader</p> <ul> <li>Queries Research Data Archive JSON API</li> <li>Downloads research dataset metadata</li> <li>Handles scientific provenance information</li> </ul>"},{"location":"architecture/#schema-layer-schemapy","title":"Schema Layer (<code>schema.py</code>)","text":"<p>Defines the unified data model using Pydantic:</p> <pre><code>USFSDocument\n\u251c\u2500\u2500 id: str           # SHA-256 hash of normalized title\n\u251c\u2500\u2500 title: str        # Dataset title\n\u251c\u2500\u2500 abstract: str     # Summary description\n\u251c\u2500\u2500 purpose: str      # Intended use (FSGeodata only)\n\u251c\u2500\u2500 description: str  # General description\n\u251c\u2500\u2500 keywords: list    # Subject keywords\n\u251c\u2500\u2500 src: str          # Source identifier\n\u2514\u2500\u2500 lineage: list     # Processing history\n</code></pre> <p>Provides:</p> <ul> <li>Data validation on ingest</li> <li>Serialization to/from JSON</li> <li>Markdown rendering for output display</li> </ul>"},{"location":"architecture/#vector-store-corepy","title":"Vector Store (<code>core.py</code>)","text":"<p>Manages semantic search capabilities via ChromaDB:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      ChromaVectorDB                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  load_document_metadata()  \u2502 Load catalog JSON                  \u2502\n\u2502  batch_load_documents()    \u2502 Index documents in batches of 100  \u2502\n\u2502  query()                   \u2502 Semantic similarity search         \u2502\n\u2502  extract_lineage_info()    \u2502 Format lineage for embedding       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Embedding Strategy</p> <p>Documents are embedded as concatenated text:</p> <pre><code>Title: {title}\nAbstract: {abstract}\nPurpose: {purpose}\nSource: {src}\nKeywords: {keywords}\nLineage: {lineage}\n</code></pre> <p>Query Flow</p> <ol> <li>User query is embedded using same model</li> <li>Cosine distance computed against all documents</li> <li>Top-k results returned with distance scores</li> <li>Lower distance = higher semantic relevance</li> </ol>"},{"location":"architecture/#llm-client-botspy","title":"LLM Client (<code>bots.py</code>)","text":"<p>Integrates with Ollama API for natural language responses:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        OllamaBot                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  System Prompt: \"Data librarian\" persona                        \u2502\n\u2502  Input: Question + Vector search context                        \u2502\n\u2502  Output: Synthesized natural language response                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>RAG Pipeline</p> <ol> <li>User submits natural language question</li> <li>Question used for vector search (retrieve top-k documents)</li> <li>Retrieved documents formatted as context</li> <li>LLM generates response grounded in catalog data</li> </ol>"},{"location":"architecture/#utilities-libpy","title":"Utilities (<code>lib.py</code>)","text":"<p>Shared helper functions:</p> Function Purpose <code>save_json()</code> Serialize data to JSON file <code>clean_str()</code> Normalize whitespace and Unicode <code>hash_string()</code> Generate SHA-256 document IDs"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#ingestion-pipeline","title":"Ingestion Pipeline","text":"<pre><code>1. Download Phase\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502FSGeodata \u2502    \u2502   GDD    \u2502    \u2502   RDA    \u2502\n   \u2502   XML    \u2502    \u2502   JSON   \u2502    \u2502   JSON   \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502               \u2502               \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u25bc\n2. Parse Phase     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502 Loaders  \u2502\n                   \u2502 parse()  \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n3. Harmonize      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502 USFSDocument \u2502\n                  \u2502    Schema    \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n4. Store          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502 catalog.json \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n5. Index          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502   ChromaDB   \u2502\n                  \u2502   Vectors    \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#query-pipeline","title":"Query Pipeline","text":"<pre><code>User Query\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Vector Search   \u2502 \u25c4\u2500\u2500\u2500 ChromaDB\n\u2502 (top-k results) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                         \u2502\n         \u25bc                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Direct Results  \u2502      \u2502  RAG Pipeline   \u2502\n\u2502 (query command) \u2502      \u2502 (chat command)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                         \u2502   Ollama LLM    \u2502\n                         \u2502   (synthesis)   \u2502\n                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                         \u2502 Natural Language\u2502\n                         \u2502    Response     \u2502\n                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>catalog/\n\u251c\u2500\u2500 src/catalog/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 cli.py          # Click CLI commands\n\u2502   \u251c\u2500\u2500 usfs.py         # Data loaders (USFS, FSGeodata, GDD, RDA)\n\u2502   \u251c\u2500\u2500 core.py         # ChromaDB vector store\n\u2502   \u251c\u2500\u2500 schema.py       # Pydantic data models\n\u2502   \u251c\u2500\u2500 bots.py         # Ollama LLM client\n\u2502   \u2514\u2500\u2500 lib.py          # Utility functions\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 usfs/\n\u2502       \u251c\u2500\u2500 fsgeodata/  # FSGeodata XML + service JSON\n\u2502       \u2502   \u251c\u2500\u2500 metadata/\n\u2502       \u2502   \u2514\u2500\u2500 services/\n\u2502       \u251c\u2500\u2500 gdd/        # GDD DCAT JSON\n\u2502       \u251c\u2500\u2500 rda/        # RDA JSON\n\u2502       \u2514\u2500\u2500 catalog.json # Unified catalog\n\u251c\u2500\u2500 chromadb/           # Vector database storage\n\u2514\u2500\u2500 docs/               # Documentation\n</code></pre>"},{"location":"architecture/#dependencies","title":"Dependencies","text":"Package Purpose click CLI framework chromadb Vector database ollama LLM API client pydantic Data validation beautifulsoup4 XML/HTML parsing requests HTTP client rich Console formatting python-dotenv Environment configuration"},{"location":"architecture/#configuration","title":"Configuration","text":"<p>Environment variables (<code>.env</code>):</p> <pre><code>OLLAMA_API_KEY=&lt;api-key&gt;\nOLLAMA_API_URL=&lt;ollama-server-url&gt;\nOLLAMA_MODEL=&lt;model-name&gt;\n</code></pre>"},{"location":"article-outline/","title":"Journal Article Outline","text":""},{"location":"article-outline/#title-suggested","title":"Title (suggested)","text":"<p>\"A Retrieval-Augmented Generation Approach for Discovering Heterogeneous Federal Geospatial Metadata\"</p>"},{"location":"article-outline/#1-introduction","title":"1. Introduction","text":"<ul> <li>Problem: Federal geospatial data fragmented across repositories with incompatible schemas</li> <li>Motivation: Researchers struggle to discover relevant USFS datasets using keyword search</li> <li>Contribution: A RAG-based system that harmonizes metadata and enables semantic discovery</li> <li>Research questions:</li> <li>Can schema harmonization improve cross-repository search?</li> <li>Does vector-based semantic search outperform keyword matching for geospatial metadata?</li> </ul>"},{"location":"article-outline/#2-background-related-work","title":"2. Background &amp; Related Work","text":"<ul> <li>Geospatial metadata standards (ISO 19115, DCAT-US, FGDC)</li> <li>Federal data discovery challenges (data.gov limitations)</li> <li>RAG architectures for information retrieval</li> <li>Vector databases for document search</li> </ul>"},{"location":"article-outline/#3-data-sources","title":"3. Data Sources","text":"<ul> <li>FSGeodata Clearinghouse (EDW) - XML/FGDC format</li> <li>Geospatial Data Discovery (GDD) - DCAT-US 1.1 JSON via ArcGIS Hub</li> <li>Research Data Archive (RDA) - Custom JSON API</li> <li>Characterization of each source's schema, coverage, and limitations</li> </ul>"},{"location":"article-outline/#4-methods","title":"4. Methods","text":"<ul> <li>Schema harmonization approach</li> <li>Vector embedding and indexing pipeline</li> <li>RAG architecture with LLM integration</li> <li>System implementation</li> </ul> <p>See <code>methods-section.md</code> for the detailed draft.</p>"},{"location":"article-outline/#5-results","title":"5. Results","text":"<ul> <li>Catalog statistics (document counts, field coverage)</li> <li>Query evaluation (semantic vs keyword search examples)</li> <li>User study or expert evaluation (if applicable)</li> </ul>"},{"location":"article-outline/#suggested-analyses","title":"Suggested Analyses","text":"<ul> <li>Table: Document counts by source</li> <li>Table: Field completeness rates across sources</li> <li>Figure: Query response comparison (keyword vs semantic)</li> <li>Example queries demonstrating semantic understanding</li> </ul>"},{"location":"article-outline/#6-discussion","title":"6. Discussion","text":"<ul> <li>Implications for federal data discovery</li> <li>Limitations:</li> <li>Embedding model choices and their impact on retrieval quality</li> <li>Information loss during schema harmonization</li> <li>Dependency on source API stability</li> <li>Generalizability to other federal repositories (EPA, NOAA, USGS)</li> </ul>"},{"location":"article-outline/#7-conclusion-future-work","title":"7. Conclusion &amp; Future Work","text":"<ul> <li>Summary of contributions</li> <li>Extensions:</li> <li>Additional data sources</li> <li>Fine-tuned embedding models for geospatial terminology</li> <li>Quantitative evaluation metrics (precision, recall, NDCG)</li> <li>User interface development</li> </ul>"},{"location":"article-outline/#target-journals-suggestions","title":"Target Journals (suggestions)","text":"<ul> <li>Computers &amp; Geosciences</li> <li>International Journal of Geographical Information Science</li> <li>Environmental Modelling &amp; Software</li> <li>Journal of the Association for Information Science and Technology (JASIST)</li> <li>Earth Science Informatics</li> </ul>"},{"location":"demos/","title":"Demos","text":"<p>Demonstration of querying the catalog for soils data in the vector database (chromadb). Right click on image and select \"Open in new tab\" for a clearer view. </p>"},{"location":"methods/","title":"Methods","text":""},{"location":"methods/#data-sources-and-collection","title":"Data Sources and Collection","text":"<p>We developed automated harvesters for three USFS geospatial data repositories, each employing distinct metadata standards and access mechanisms.</p> <p>FSGeodata Clearinghouse. The Enterprise Data Warehouse (EDW) datasets are accessed via the USFS Geodata portal (https://data.fs.usda.gov/geodata/edw/datasets.php). We implemented a web scraper using BeautifulSoup to parse the datasets index page, extracting links to XML metadata files conforming to FGDC Content Standard for Digital Geospatial Metadata. For each dataset, we retrieve both the metadata XML and, where available, associated ArcGIS MapServer service descriptors in JSON format. A rate limiter (250ms delay) ensures compliance with server policies.</p> <p>Geospatial Data Discovery (GDD). The USFS ArcGIS Hub portal exposes a DCAT-US 1.1 compliant feed at a single JSON endpoint (https://data-usfs.hub.arcgis.com/api/feed/dcat-us/1.1.json). This feed provides dataset titles, descriptions, keywords, and thematic classifications in a standardized federal open data format.</p> <p>Research Data Archive (RDA). The USFS Research Data Archive provides a JSON web service (https://www.fs.usda.gov/rds/archive/webservice/datagov) returning dataset metadata including titles, descriptions, and keyword arrays. This source emphasizes research datasets with scientific provenance.</p>"},{"location":"methods/#schema-harmonization","title":"Schema Harmonization","text":"<p>To enable cross-repository search, we defined a unified document schema (<code>USFSDocument</code>) with the following fields:</p> Field Type Description <code>id</code> string SHA-256 hash of normalized title (lowercase, trimmed) <code>title</code> string Dataset title <code>abstract</code> string Summary description (mapped from FGDC abstract or DCAT description) <code>purpose</code> string Intended use statement (FSGeodata only) <code>description</code> string General description text <code>keywords</code> array Subject keywords (from themekey, keyword, or theme fields) <code>src</code> string Source identifier: \"fsgeodata\", \"gdd\", or \"rda\" <code>lineage</code> array Processing history with dates (FSGeodata only) <p>The <code>id</code> field serves as a deduplication key, ensuring datasets appearing in multiple repositories are not double-counted. Text fields undergo normalization including whitespace collapsing and Unicode standardization via a <code>clean_str()</code> utility function.</p> <p>Schema Mapping. Each source requires distinct parsing logic:</p> <ul> <li>FSGeodata: XML parsing extracts <code>&lt;title&gt;</code>, <code>&lt;descript&gt;&lt;abstract&gt;</code>, <code>&lt;descript&gt;&lt;purpose&gt;</code>, <code>&lt;themekey&gt;</code>, and <code>&lt;procstep&gt;</code> elements</li> <li>GDD: JSON mapping from DCAT fields (<code>title</code>, <code>description</code>, <code>keyword</code>, <code>theme</code>)</li> <li>RDA: Direct JSON field extraction (<code>title</code>, <code>description</code>, <code>keyword</code>)</li> </ul>"},{"location":"methods/#vector-embedding-and-storage","title":"Vector Embedding and Storage","text":"<p>Harmonized documents are loaded into ChromaDB, an open-source vector database. For each document, we construct an embedding input string concatenating:</p> <pre><code>Title: {title}\nAbstract: {abstract}\nPurpose: {purpose}\nSource: {src}\nKeywords: {keywords}\nLineage: {lineage}\n</code></pre> <p>ChromaDB's default embedding model generates vector representations stored alongside document metadata. Documents are processed in batches of 100 to optimize memory usage. The collection is rebuilt from scratch on each indexing operation to ensure consistency.</p>"},{"location":"methods/#retrieval-augmented-generation","title":"Retrieval-Augmented Generation","text":"<p>The system supports two query modes:</p> <p>Vector Search. Users submit natural language queries, which are embedded and compared against the document collection using cosine distance. The top-k results (configurable, default k=5) are returned with relevance distances, where lower distances indicate higher semantic similarity.</p> <p>LLM-Augmented Discovery. For complex discovery questions, we implement a RAG pipeline:</p> <ol> <li>The user query is used to retrieve the top-k relevant documents via vector search</li> <li>Retrieved documents are formatted as context</li> <li>The query and context are submitted to an LLM (configurable via Ollama API)</li> <li>The LLM generates a natural language response synthesizing the search results</li> </ol> <p>The LLM system prompt frames the model as a \"data librarian\" with instructions to:</p> <ul> <li>List relevant datasets with explanations of relevance</li> <li>Prioritize results by distance score (lower = more relevant)</li> <li>Provide direct yes/no answers for existence queries</li> <li>Avoid speculation beyond catalog contents</li> </ul>"},{"location":"methods/#implementation","title":"Implementation","text":"<p>The system is implemented in Python as a CLI tool using the Click framework. Key dependencies include:</p> <ul> <li>ChromaDB for vector storage and similarity search</li> <li>Ollama client for LLM integration</li> <li>BeautifulSoup for XML/HTML parsing</li> <li>Pydantic for schema validation</li> <li>Requests for HTTP operations</li> </ul> <p>The modular architecture separates concerns: data loaders (<code>usfs.py</code>), schema definitions (<code>schema.py</code>), vector operations (<code>core.py</code>), and LLM integration (<code>bots.py</code>).</p>"},{"location":"methods/#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Data Collection                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   FSGeodata     \u2502        GDD          \u2502          RDA            \u2502\n\u2502   (XML/FGDC)    \u2502    (DCAT-US 1.1)    \u2502        (JSON)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                   \u2502                       \u2502\n         \u25bc                   \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Schema Harmonization                         \u2502\n\u2502                      (USFSDocument)                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Unified Catalog (JSON)                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Vector Embedding &amp; Indexing                     \u2502\n\u2502                        (ChromaDB)                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Vector Search       \u2502     \u2502      LLM-Augmented Discovery    \u2502\n\u2502   (Semantic Queries)    \u2502     \u2502     (Natural Language Q&amp;A)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}