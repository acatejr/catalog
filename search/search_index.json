{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Catalog Documentation","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The United States Forest Service (USFS) has vast amounts of spatial and tabular data used in managing the United States' National Forest resources as well as data used to manage the USFS internal operations.  USFS has several enterprise-scale data management systems used to manage and publish data.  The USFS is also mandated to apply metadata standards to its data set in order to comply with US Federal Government Acts that include:</p> <ul> <li>2002 E-Government Act</li> <li>2018 Evidence Act</li> <li>2018 The Geospatial Data Act (GDA)</li> </ul> <p>This project is a proof-of-concept project that harvests metadata from different USFS systems in order to build a catalog system that allows users to ask questions like:</p> <ul> <li>What data fields does are in a spatial fire dataset?</li> <li>What is the data lineage of a field in a dataset (sptial and/or tabular)?</li> <li>Where can data set be found?</li> <li>What data sets might be useful in order to build a data dashboard for tracking and monitoring timber harvests?</li> </ul>"},{"location":"data-harvesting/","title":"Data Harvesting","text":"<p>The project required input data which comes from the following USFS metadata sources:</p> <ol> <li> <p>FSGeodata Clearing House - Data collected and managed by Forest Service programs is available in a map service and two downloadable file formats \u2013 in a shape file and an ESRI file geodatabase. Metadata is available that describes the content, source, and currency of the data. You can filter the list by the topic categories in the menu at the left to help you find information you are interested in. You can view the feature classes in a single dataset by clicking on the name of the parent dataset at the bottom of the abstract.</p> </li> <li> <p>Datahub - A U.S. Forest Service configured open data site to help partners and the public discover geospatial data published by the Agency. Used together with user data to create maps, apps and other information products.</p> </li> <li> <p>Research Data Archive (RDA) - he FS Research Data Archive offers a catalog of hundreds of research datasets funded by Forest Service Research and Development (FS R&amp;D) or by the Joint Fire Science Program (JFSP). Of special interest, our collection includes long-term datasets from a number of Forest Service Experimental Forests, Ranges, and Watersheds (FS EFRs).</p> </li> </ol> <p>Each of the sources provided metadata in XML or JSON format.  A command line tool was written to harvest the metadata from those data sources.</p> <p>The command line data harvester downloads metadata sources and parses each metadata item into a json object.</p> <pre><code>{\n        \"id\": \"7ce585693437c8f937073065960c398cf2a0aa96ed686ad63264bd9befc129d7\",\n        \"title\": \"Characterizing Ecoregions and Montane Perennial Watersheds of the Great Basin - Watersheds\",\n        \"description\": \"Multiple research and management partners collaboratively developed a multiscale approach for assessing the geomorphic sensitivity of streams and ecological resilience of riparian and meadow ecosystems in upland watersheds of the Great Basin to disturbances and management actions. The approach builds on long-term work by the partners on the responses of these systems to disturbances and management actions. At the core of the assessments is information on past and present watershed and stream channel characteristics, geomorphic and hydrologic processes, and riparian and meadow vegetation. In this report, we describe the approach used to delineate Great Basin mountain ranges and the watersheds within them, and the data that are available for the individual watersheds. We also describe the resulting database and the data sources. Furthermore, we summarize information on the characteristics of the regions and watersheds within the regions and the implications of the assessments for geomorphic sensitivity and ecological resilience. The target audience for this multiscale approach is managers and stakeholders interested in assessing and adaptively managing Great Basin stream systems and riparian and meadow ecosystems. Anyone interested in delineating the mountain ranges and watersheds within the Great Basin or quantifying the characteristics of the watersheds will be interested in this report. For more information, visit: https://www.fs.usda.gov/research/treesearch/61573\",\n        \"metadata_source_url\": \"https://data.fs.usda.gov/geodata/edw/edw_resources/meta/S_USA.Hydro_GrBasin_Watersheds.xml\",\n        \"keywords\": [\n            \"inlandWaters\",\n            \"geoscientificInformation\",\n            \"environment\",\n            \"riparian\",\n            \"fire\",\n            \"geomorphology\",\n            \"meadows\",\n            \"mountain range delineation\",\n            \"Great Basin watershed database\",\n            \"Great Basin watershed characteristics\",\n            \"watershed delineation\",\n            \"climate\",\n            \"species\",\n            \"Great Basin\",\n            \"ecosystem resistance and resilience\",\n            \"hydrology\",\n            \"watersheds\"\n        ],\n        \"src\": \"fsgeodata\"\n},\n</code></pre> <p>Each json item is stored in a PostgreSQL database table.  The database table has a vector column that stores each items embeddings.  An item's embeddings are computed using title, description, keywords, and src fields.  The metadata loading process also scan the XML and JSON input for data schema information (entity attribute information).  The schema information is used to enhance the vector searching so that queries about data table names, field names and types... can be processed.  An early version of the data harvesting and importing tool only harvested basic data like title, description and keywords.  Claude Code was used to enhance the code so the harvester would include schema information.</p> <p>As each item, which is stored as a document in a table named documents, is saved or edited an embedding values are calculated and stored in an embeddings column.  Embeddings values are computed based on the sentence transformier <code>all-MiniLM-L6-v2</code>.  The transformer was chosen arbitrarily.  Further exploration into an appropriate transformer should be part of future improvements.</p>"}]}